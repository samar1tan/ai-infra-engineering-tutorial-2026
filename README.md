# ai-infra-engineering-tutorial-2026
My journey from Backend to AI Infra Engineer.

## 人才画像
这份战略目标书旨在为一名具备扎实系统基础（CMU研究生级别）及大模型应用经验，但缺乏 AI Infra 工业界实战背书的普通后端工程师，勾勒出蜕变为顶尖大模型公司（如深度求索 DeepSeek）核心系统高级研发工程师的**最终人才画像**。

结合视频中提到的大厂 AI 平台与训练工程师的核心痛点（计算、通信、存储调度优化），以及 DeepSeek 强调的“极致性能榨取”、“软硬件协同”与“专家深度+架构广度”，你需要通过自学和深度实践，最终将自己塑造成**“具备顶层算法业务感知力，底盘扎根于分布式系统与高性能计算的硬核系统工程师”**。

---

### 第一部分：核心技能领域与具体技能点架构

针对 DeepSeek “专家深度 + 架构视野”的要求，你需要构建 **1个主攻方向（破局点） + 2个辅助方向（护城河） + 1个通用底层（基本盘）** 的技能矩阵。由于你拥有传统分布式后端的系统基础，建议以**“分布式训练与通信优化”**或**“大规模集群调度与存储”**作为主攻的领域专家切入点。

#### 领域一：大规模分布式训练框架与并行策略（核心主攻 - P0）
*大模型训练的基础设施，直接决定模型迭代的效率。*
*   **3D/4D 并行策略底层机制**：深入理解 Data Parallelism (DP/DDP/ZeRO1-3/FSDP)、Tensor Parallelism (TP)、Pipeline Parallelism (PP) 的数学原理与显存/通信开销模型。特别是针对 DeepSeek 核心的 Mixture of Experts (MoE) 架构的 Expert Parallelism (EP)。
*   **主流开源框架源码级理解**：Megatron-LM, DeepSpeed, vLLM (推理端)。不能仅仅停留在 API 调用，需要理解其底层的算子切分逻辑、通信原语注入时机。
*   **显存优化技术**：Activation Checkpointing (重计算), CPU Offloading, 显存碎片管理 (如 PagedAttention 的底层机制)。

#### 领域二：高性能网络通信与拓扑感知（核心主攻 - P0）
*对应视频中提及的 Networking 优化，大模型训练集群最容易成为瓶颈的一环。结合你优秀的系统课背景，这是最好的切入点。*
*   **集合通信原语（Collective Communication）**：彻底弄懂 All-Reduce, All-Gather, Reduce-Scatter, Broadcast 的内部算法实现（如 Ring, Tree, Butterfly），以及它们在不同并行策略中的触发时机和通信量计算。
*   **通信与计算重叠（Overlap）**：掌握通信调度的核心思想（如视频中提到的 ByteScheduler），如何通过 CUDA Stream 和框架层的计算图调度，让前向/反向传播的矩阵乘法与网络通信并行执行。
*   **底层网络协议与拓扑**：理解 RDMA (RoCEv2, InfiniBand) 的机制；理解单机内 NVLink/NVSwitch 拓扑，以及机架间胖树（Fat-Tree）拓扑对通信路由调度的影响。

#### 领域三：异构计算与算子优化（高阶进阶 - P1）
*DeepSeek JD 强调“榨干硬件点滴性能”，需要深入 GPU 架构。*
*   **CUDA 编程模型基础**：GPU 内存层次结构（Global, Shared, Registers）、Thread/Block/Warp 调度机制、Memory Coalescing（内存合并访问）、Bank Conflict。
*   **AI 编译器基础**：了解 Triton 语言及其编译机制。Triton 是目前高性价比改写算子的利器，能够编写媲美手写 CUDA 的算子（如 FlashAttention 的 Triton 实现）。
*   **Profile 与性能分析**：熟练使用 Nsight Systems (nsys), Nsight Compute (ncu), PyTorch Profiler，能够从底层视角看清系统 Timeline 上的空白（Idle）并在代码层定位原因。

#### 领域四：大规模集群调度与容错保障（工程基础 - P1）
*对应视频中的训练平台基本要素，解决数百台机器协同的工程稳定性问题。*
*   **多租户调度与资源分配**：理解 Kubernetes, Slurm 等调度系统的核心机制。理解如何针对视频提到的 JCT (Job Completion Time) 和 Makespan 指标进行拓扑感知的任务调度。
*   **容错与弹性（Fault Tolerance）**：大模型训练必然遇到硬件故障。掌握同步训练下的快速 Checkpoint/Restore 机制、异步保存、以及检测到硬件掉线后的自动容灾漂移设计。
*   **高吞吐数据流**：应对 Dataloader 在数百张卡上的读取瓶颈，理解并行文件系统，以及从数据预处理到显存的 Zero-copy 数据流。

#### 领域五：底层系统编程与代码品味（基本盘 - P0）
*DeepSeek 基本要求第一条。*
*   **Modern C++ (14/17/20)**：大模型 Infra 底层（如 PyTorch C++ 拓展、自定义算子、通信库）的必备语言。要求极高的内存安全意识和极致的性能嗅觉。
*   **Python 内部机制与 C/C++ 互操作**：理解 GIL, CPython 内存管理，Pybind11，能够自如地在 Python 框架层与 C++ 性能层穿梭。
*   **无锁编程与并发控制**：操作系统级别的线程调度、原子操作、内存屏障。

---

### 第二部分：各技能领域的学习优先级与战略定位

| 优先级 | 技能领域 | 战略定位与自学重点 |
| :--- | :--- | :--- |
| **P0 (生存基石)** | 分布式框架与并行策略 | **必考题**。自学策略：从手推各种并行的显存占用和通信量公式开始，随后精读 Megatron-LM 源码。利用你的 Agent 背景，思考大模型每一层的输入输出在多卡间如何切分。 |
| **P0 (决胜长板)** | 高性能网络通信 | **利用 CMU 系统课背景实现降维打击**。自学策略：深入研究 NCCL 原理与 RDMA 网络。这是很多纯算法/纯后端工程师的盲区，如果你能清晰阐述如何根据网络拓扑做调度，将极大增加说服力。 |
| **P0 (代码品味)** | 底层系统编程 | **一票否决项**。大厂极为看重代码质量，尤其是 DeepSeek。自学策略：用 C++ 重写一些极简版的轮子，培养对纳秒级延迟和字节级内存的敏感度。 |
| **P1 (潜力展现)** | 异构计算与算子优化 | **证明“榨干性能”潜力的得分点**。不需要成为写 PTX 汇编的极客，但必须掌握 Triton 编写常见算子（如 Fused LayerNorm, Attention）。自学策略：啃透 FlashAttention 原理并复现其简化版。 |
| **P1 (工程视野)** | 集群调度与容错存储 | **体现全局架构观**。自学策略：结合传统后端高可用架构经验，研究大模型场景下（状态极重、同步阻塞）的容错机制有何不同，提出针对性解决方案。 |

---

### 第三部分：面试场景画像（7轮面试的实战拆解与能力预期）

在没有任何顶会论文和顶级开源项目背书的情况下，面试官对你的初始假设是“懂传统系统的熟练工”。你需要通过这七轮面试，展现出**“理论吃透、能推公式、能看懂源码、有实操洞察”**的硬核实力。

#### 1. 编码能力与系统素养局（通常为前 2 轮）
*   **考察重点**：并非单纯的 LeetCode。会考察带有系统背景的编程，例如：实现一个多线程安全的高性能内存池；实现一个无锁队列；或者写一个类似 Ring All-Reduce 的拓扑模拟代码。
*   **你需要达到的水平**：C++ 代码不仅要 Bug-free，还要展现出对缓存行失效（Cache Line Bouncing）、内存对齐、零拷贝（Zero-copy）的深刻理解。这证明你的 JD 基本要求：“优秀的设计能力和代码品味”。

#### 2. AI 系统架构与计算推演局（通常为第 3-4 轮）
*   **考察重点**：纸上谈兵的深度。面试官会给出具体场景：“现在要训练一个千亿参数 MoE 模型，集群有 1024 张 H100，网络是两层胖树，请设计并行策略，并估算每一步的通信时间和显存峰值。”
*   **你需要达到的水平**：能够熟练地在白板上（或共享屏幕）写出模型状态（Weights, Gradients, Optimizer states）的显存占用公式。能够准确计算在给定 TP=8, PP=4, DP=32 下，每一次 Forward 和 Backward 阶段网络上需要传输多少 Byte 的数据，耗时大概多少，受限于算力还是受限于带宽。**这是体现你虽然没做过，但已经把理论吃得极透的黄金时刻。**

#### 3. 领域深度与疑难杂症局（通常为第 5-6 轮，资深专家面）
*   **考察重点**：排错能力和极端优化（JD 中的“榨干硬件”）。面试官会抛出生产环境的真实问题：“发现训练中途某个 step GPU 利用率突然掉到 0 持续了几百毫秒，你怎么排查？”或者“现有的通信计算重叠策略在某一层失效了，为什么？”
*   **你需要达到的水平**：展现出工具链的熟练度（如回答通过 nsys 抓取 timeline，查看是 CPU dataloader 阻塞，还是某个通信原语未启动，或是 D2D 内存拷贝造成的 stall）。如果你在自学时用几张消费级显卡或租用云端多卡做过真实的 Profiling 和瓶颈分析，这里的回答会非常具有实战画面感。

#### 4. 技术视野与主管局（第 7 轮）
*   **考察重点**：自我驱动力、快速学习能力以及对 AGI 的认知。会挑战你的劣势：“你之前做 Agent 应用层，为什么转到底层 Infra？你觉得自己能适应吗？”
*   **你需要达到的水平**：巧妙转化劣势。你的逻辑应该是：“正因为我深度做过 Agent，我知道 LLM 落地时 Context Window 不断扩大对 KV Cache 和推理延迟造成的灾难性影响，也知道 MoE 对于应用的巨大价值。这让我意识到 AGI 的瓶颈已经完全转移到了底层系统优化上。我凭借 CMU 扎实的 OS 和网络基础，在过去几个月里吃透了 Megatron 的源码并精通了 Triton 编程，我具备从业务痛点（Top-down）直达硬件底层（Bottom-up）的完整视野，这比纯粹做底层的工程师具有更好的目标感，我完全能在 1-2 个月内补齐业务实操的拼图。”

### 结语与执行建议

这幅人才画像的门槛极高，但对于拥有扎实 CS 基础的人来说并非不可逾越。由于你缺乏背书，**你的“投名状”不应该是简历上的空话，而必须是硬核的产出**。

**三个月的破局建议：**
不要泛泛而读。挑一个特定的痛点（例如：优化某种特定的 Transformer 变体的通信开销，或者用 Triton 重新写一个融合算子），在 Github 上开源你的分析过程、公式推导、Timeline 截图和对比代码。把这个硬核的分析报告挂在简历显眼处。当你能在面试中指着自己的分析图表与 DeepSeek 的专家探讨时，你就不再是一个“想转行的后端工程师”，而是一个“带着诚意和实力的准入职者”。
